{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_test_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQezAX9PsnhK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT68KhWntnWq",
        "outputId": "9595852d-bb82-457b-dcd4-d14a3fbafe85"
      },
      "source": [
        "!mkdir -p run/vae/\n",
        "%cd /data_train/\n",
        "!pwd\n",
        "!unzip Training_samples.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/data_train/'\n",
            "/content\n",
            "/content\n",
            "unzip:  cannot find or open Training_samples.zip, Training_samples.zip.zip or Training_samples.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2xNSpTr-a1l"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "#### CALLBACKS\n",
        "class CustomCallback(Callback):\n",
        "    \n",
        "    def __init__(self, run_folder, print_every_n_batches, initial_epoch, vae):\n",
        "        self.epoch = initial_epoch\n",
        "        self.run_folder = run_folder\n",
        "        self.print_every_n_batches = print_every_n_batches\n",
        "        self.vae = vae\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs={}):  \n",
        "        if batch % self.print_every_n_batches == 0:\n",
        "            z_new = np.random.normal(size = (1,self.vae.z_dim))\n",
        "            reconst = self.vae.decoder.predict(np.array(z_new))[0].squeeze()\n",
        "\n",
        "            filepath = os.path.join(self.run_folder, 'images', 'img_' + str(self.epoch).zfill(3) + '_' + str(batch) + '.jpg')\n",
        "            if len(reconst.shape) == 2:\n",
        "                plt.imsave(filepath, reconst, cmap='gray_r')\n",
        "            else:\n",
        "                plt.imsave(filepath, reconst)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch += 1\n",
        "\n",
        "\n",
        "\n",
        "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n",
        "    '''\n",
        "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
        "    '''\n",
        "    def schedule(epoch):\n",
        "        new_lr = initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
        "        \n",
        "        return new_lr\n",
        "\n",
        "    return LearningRateScheduler(schedule)\n",
        "\n",
        "class Sampling(Layer):\n",
        "    def call(self, inputs):\n",
        "        mu, log_var = inputs\n",
        "        epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
        "        return mu + K.exp(log_var / 2) * epsilon\n",
        "\n",
        "\n",
        "class VAEModel(Model):\n",
        "    def __init__(self, encoder, decoder, r_loss_factor, **kwargs):\n",
        "        super(VAEModel, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.r_loss_factor = r_loss_factor\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.square(data - reconstruction), axis = [1,2,3]\n",
        "            )\n",
        "            reconstruction_loss *= self.r_loss_factor\n",
        "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "            kl_loss = tf.reduce_sum(kl_loss, axis = 1)\n",
        "            kl_loss *= -0.5\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }\n",
        "\n",
        "    def call(self,inputs):\n",
        "        latent = self.encoder(inputs)\n",
        "        return self.decoder(latent)\n",
        "\n",
        "\n",
        "class VariationalAutoencoder():\n",
        "    def __init__(self\n",
        "        , input_dim\n",
        "        , encoder_conv_filters\n",
        "        , encoder_conv_kernel_size\n",
        "        , encoder_conv_strides\n",
        "        , decoder_conv_t_filters\n",
        "        , decoder_conv_t_kernel_size\n",
        "        , decoder_conv_t_strides\n",
        "        , z_dim\n",
        "        , r_loss_factor\n",
        "        , use_batch_norm = False\n",
        "        , use_dropout= False\n",
        "        ):\n",
        "\n",
        "        self.name = 'variational_autoencoder'\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.encoder_conv_filters = encoder_conv_filters\n",
        "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
        "        self.encoder_conv_strides = encoder_conv_strides\n",
        "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
        "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
        "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
        "        self.z_dim = z_dim\n",
        "        self.r_loss_factor = r_loss_factor\n",
        "\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "        self.use_dropout = use_dropout\n",
        "\n",
        "        self.n_layers_encoder = len(encoder_conv_filters)\n",
        "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def _build(self):\n",
        "        \n",
        "        ### THE ENCODER\n",
        "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
        "\n",
        "        x = encoder_input\n",
        "\n",
        "        for i in range(self.n_layers_encoder):\n",
        "            conv_layer = Conv2D(\n",
        "                filters = self.encoder_conv_filters[i]\n",
        "                , kernel_size = self.encoder_conv_kernel_size[i]\n",
        "                , strides = self.encoder_conv_strides[i]\n",
        "                , padding = 'same'\n",
        "                , name = 'encoder_conv_' + str(i)\n",
        "                )\n",
        "\n",
        "            x = conv_layer(x)\n",
        "\n",
        "            if self.use_batch_norm:\n",
        "                x = BatchNormalization()(x)\n",
        "\n",
        "            x = LeakyReLU()(x)\n",
        "\n",
        "            if self.use_dropout:\n",
        "                x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "        shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "        x = Flatten()(x)\n",
        "        self.mu = Dense(self.z_dim, name='mu')(x)\n",
        "        self.log_var = Dense(self.z_dim, name='log_var')(x)\n",
        "\n",
        "        self.z = Sampling(name='encoder_output')([self.mu, self.log_var])\n",
        "\n",
        "        self.encoder = Model(encoder_input, [self.mu, self.log_var, self.z], name = 'encoder')\n",
        "        \n",
        "        \n",
        "\n",
        "        ### THE DECODER\n",
        "\n",
        "        decoder_input = Input(shape=(self.z_dim,), name='decoder_input')\n",
        "        x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "        x = Reshape(shape_before_flattening)(x)\n",
        "\n",
        "        for i in range(self.n_layers_decoder):\n",
        "            conv_t_layer = Conv2DTranspose(\n",
        "                filters = self.decoder_conv_t_filters[i]\n",
        "                , kernel_size = self.decoder_conv_t_kernel_size[i]\n",
        "                , strides = self.decoder_conv_t_strides[i]\n",
        "                , padding = 'same'\n",
        "                , name = 'decoder_conv_t_' + str(i)\n",
        "                )\n",
        "\n",
        "            x = conv_t_layer(x)\n",
        "\n",
        "            if i < self.n_layers_decoder - 1:\n",
        "                if self.use_batch_norm:\n",
        "                    x = BatchNormalization()(x)\n",
        "                x = LeakyReLU()(x)\n",
        "                if self.use_dropout:\n",
        "                    x = Dropout(rate = 0.25)(x)\n",
        "            else:\n",
        "                x = Activation('sigmoid')(x)\n",
        "\n",
        "            \n",
        "\n",
        "        decoder_output = x\n",
        "\n",
        "        self.decoder = Model(decoder_input, decoder_output, name = 'decoder')\n",
        "        print(decoder_input)\n",
        "        ### THE FULL VAE\n",
        "\n",
        "        self.model = VAEModel(self.encoder, self.decoder, self.r_loss_factor)\n",
        "\n",
        "\n",
        "\n",
        "    def compile(self, learning_rate):\n",
        "        self.learning_rate = learning_rate\n",
        "        optimizer = Adam(lr=learning_rate)\n",
        "        self.model.compile(optimizer=optimizer)\n",
        "\n",
        "\n",
        "    def save(self, folder):\n",
        "\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)\n",
        "            os.makedirs(os.path.join(folder, 'viz'))\n",
        "            os.makedirs(os.path.join(folder, 'weights'))\n",
        "            os.makedirs(os.path.join(folder, 'images'))\n",
        "\n",
        "        with open(os.path.join(folder, 'params.pkl'), 'wb') as f:\n",
        "            pickle.dump([\n",
        "                self.input_dim\n",
        "                , self.encoder_conv_filters\n",
        "                , self.encoder_conv_kernel_size\n",
        "                , self.encoder_conv_strides\n",
        "                , self.decoder_conv_t_filters\n",
        "                , self.decoder_conv_t_kernel_size\n",
        "                , self.decoder_conv_t_strides\n",
        "                , self.z_dim\n",
        "                , self.use_batch_norm\n",
        "                , self.use_dropout\n",
        "                ], f)\n",
        "\n",
        "        self.plot_model(folder)\n",
        "\n",
        "\n",
        "    def load_weights(self, filepath):\n",
        "        self.model.load_weights(filepath)\n",
        "\n",
        "    def train(self, x_train, batch_size, epochs, run_folder, print_every_n_batches = 100, initial_epoch = 0, lr_decay = 1):\n",
        "\n",
        "        custom_callback = CustomCallback(run_folder, print_every_n_batches, initial_epoch, self)\n",
        "        lr_sched = step_decay_schedule(initial_lr=self.learning_rate, decay_factor=lr_decay, step_size=1)\n",
        "        \n",
        "        checkpoint_filepath=os.path.join(run_folder, \"weights/weights-{epoch:03d}-{loss:.2f}.h5\")\n",
        "        checkpoint1 = ModelCheckpoint(checkpoint_filepath, save_weights_only = True, verbose=1)\n",
        "        checkpoint2 = ModelCheckpoint(os.path.join(run_folder, 'weights/weights.h5'), save_weights_only = True, verbose=1)\n",
        "\n",
        "        callbacks_list = [checkpoint1, checkpoint2, custom_callback, lr_sched]\n",
        "\n",
        "        self.model.fit(     \n",
        "            x_train\n",
        "            , x_train\n",
        "            , batch_size = batch_size\n",
        "            , shuffle = True\n",
        "            , epochs = epochs\n",
        "            , initial_epoch = initial_epoch\n",
        "            , callbacks = callbacks_list\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def train_with_generator(self, data_flow, epochs, steps_per_epoch, run_folder, print_every_n_batches = 100, initial_epoch = 0, lr_decay = 1, ):\n",
        "        custom_callback = CustomCallback(run_folder, print_every_n_batches, initial_epoch, self)\n",
        "        lr_sched = step_decay_schedule(initial_lr=self.learning_rate, decay_factor=lr_decay, step_size=1)\n",
        "        checkpoint_filepath=os.path.join(run_folder, \"weights/weights-{epoch:03d}-{loss:.2f}.h5\")\n",
        "        checkpoint1 = ModelCheckpoint(checkpoint_filepath, save_weights_only = True, verbose=1)\n",
        "        checkpoint2 = ModelCheckpoint(os.path.join(run_folder, 'weights/weights.h5'), save_weights_only = True, verbose=1)\n",
        "        callbacks_list = [checkpoint1, checkpoint2, custom_callback, lr_sched]\n",
        "        self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\n",
        "\n",
        "        self.model.fit(\n",
        "            data_flow\n",
        "            , shuffle = True\n",
        "            , epochs = epochs\n",
        "            , initial_epoch = initial_epoch\n",
        "            , callbacks = callbacks_list\n",
        "            , steps_per_epoch=steps_per_epoch \n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    def plot_model(self, run_folder):\n",
        "        plot_model(self.model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n",
        "        plot_model(self.encoder, to_file=os.path.join(run_folder ,'viz/encoder.png'), show_shapes = True, show_layer_names = True)\n",
        "        plot_model(self.decoder, to_file=os.path.join(run_folder ,'viz/decoder.png'), show_shapes = True, show_layer_names = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPFiADFp0DF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479459f0-144e-41e4-aae9-6ee94a3237f8"
      },
      "source": [
        "%cd /content/\n",
        "!pwd\n",
        "#from utils.callbacks import CustomCallback, step_decay_schedule \n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GerpZvXStsPa"
      },
      "source": [
        "# run params\n",
        "section = 'vae'\n",
        "run_id = '0001'\n",
        "data_name = 'bldg_train'\n",
        "RUN_FOLDER = 'run/{}/'.format(section)\n",
        "RUN_FOLDER += '_'.join([run_id, data_name])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "mode =  'build' #'load' #\n",
        "\n",
        "\n",
        "DATA_FOLDER = \"/content/all_data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJgyd52r5_FG",
        "outputId": "26dbc74d-0331-4ec6-bba0-683bd01e5222"
      },
      "source": [
        "%cd /content/\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4CtOb9ivmT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee4afff-d0a2-4daa-eb5d-d907551908ae"
      },
      "source": [
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "INPUT_DIM = (100,100,3)\n",
        "BATCH_SIZE = 30\n",
        "\n",
        "filenames = np.array(glob(\"*.jpg\"))\n",
        "\n",
        "NUM_IMAGES = len(filenames)\n",
        "print(NUM_IMAGES)\n",
        "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
        "                                         , target_size = INPUT_DIM[:2]\n",
        "                                         , color_mode=\"rgb\"\n",
        "                                         , batch_size = BATCH_SIZE\n",
        "                                         , shuffle = True\n",
        "                                         , class_mode = \"input\"\n",
        "                                         , subset = \"training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Found 3001 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDfXJsODSS_h",
        "outputId": "eb0c3528-37d3-494b-e589-d18416ffcd0e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "619ecTYtt0Yo",
        "outputId": "26a786a3-c4b1-4dd0-81f7-4698056da853"
      },
      "source": [
        "vae = VariationalAutoencoder(\n",
        "    input_dim = INPUT_DIM\n",
        "    , encoder_conv_filters = [32,64,64,64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,3]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 100\n",
        "    , r_loss_factor = 10000\n",
        "    , use_batch_norm=True\n",
        "    , use_dropout=True\n",
        ")\n",
        "\n",
        "if mode == 'build':\n",
        "    vae.save(RUN_FOLDER)\n",
        "else:\n",
        "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='decoder_input'), name='decoder_input', description=\"created by layer 'decoder_input'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qap_a5sDt2ZD",
        "outputId": "68611f7c-eb46-46f9-9172-8f3db8bd34d2"
      },
      "source": [
        "\n",
        "vae.encoder.summary()\n",
        "vae.decoder.summary()\n",
        "for layer in vae.model.layers:\n",
        "  print(layer.input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 100, 100, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_0 (Conv2D)         (None, 100, 100, 32) 896         encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 100, 100, 32) 128         encoder_conv_0[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_144 (LeakyReLU)     (None, 100, 100, 32) 0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 100, 100, 32) 0           leaky_re_lu_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_1 (Conv2D)         (None, 50, 50, 64)   18496       dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 50, 50, 64)   256         encoder_conv_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_145 (LeakyReLU)     (None, 50, 50, 64)   0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 50, 50, 64)   0           leaky_re_lu_145[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_2 (Conv2D)         (None, 25, 25, 64)   36928       dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 25, 25, 64)   256         encoder_conv_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_146 (LeakyReLU)     (None, 25, 25, 64)   0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 25, 25, 64)   0           leaky_re_lu_146[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_conv_3 (Conv2D)         (None, 25, 25, 64)   36928       dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 25, 25, 64)   256         encoder_conv_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_147 (LeakyReLU)     (None, 25, 25, 64)   0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 25, 25, 64)   0           leaky_re_lu_147[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 40000)        0           dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 100)          4000100     flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "log_var (Dense)                 (None, 100)          4000100     flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "encoder_output (Sampling)       (None, 100)          0           mu[0][0]                         \n",
            "                                                                 log_var[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,094,344\n",
            "Trainable params: 8,093,896\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 40000)             4040000   \n",
            "_________________________________________________________________\n",
            "reshape_20 (Reshape)         (None, 25, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_0 (Conv2DTran (None, 25, 25, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_141 (Bat (None, 25, 25, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_148 (LeakyReLU)  (None, 25, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_141 (Dropout)        (None, 25, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_1 (Conv2DTran (None, 50, 50, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_142 (Bat (None, 50, 50, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_149 (LeakyReLU)  (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_142 (Dropout)        (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_2 (Conv2DTran (None, 100, 100, 32)      18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_143 (Bat (None, 100, 100, 32)      128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_150 (LeakyReLU)  (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_143 (Dropout)        (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_3 (Conv2DTran (None, 100, 100, 3)       867       \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 100, 100, 3)       0         \n",
            "=================================================================\n",
            "Total params: 4,133,827\n",
            "Trainable params: 4,133,507\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name='encoder_input'), name='encoder_input', description=\"created by layer 'encoder_input'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='decoder_input'), name='decoder_input', description=\"created by layer 'decoder_input'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nHhmfp1t6sm"
      },
      "source": [
        "LEARNING_RATE = 0.0005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ODFNl80t9Jc",
        "outputId": "40f461db-a3c5-4b69-ef22-5abffad469ff"
      },
      "source": [
        "vae.compile(LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axS3mUcwt_wB"
      },
      "source": [
        "EPOCHS = 1\n",
        "PRINT_EVERY_N_BATCHES = 100\n",
        "INITIAL_EPOCH = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYb8vJvy18bT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a813da-9a04-49a2-b626-e13c287c9aa5"
      },
      "source": [
        "vae.model.summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <__main__.VAEModel object at 0x7f9571200310>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "enKcr64puADY",
        "outputId": "511478b0-4165-4c36-dbca-cb58541676e4"
      },
      "source": [
        "vae.train_with_generator(     \n",
        "    data_flow\n",
        "    , epochs = EPOCHS\n",
        "    , steps_per_epoch = 3000 / BATCH_SIZE\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hellooo!\n",
            "hellooo!\n",
            "hellooo!\n",
            "hellooo!\n",
            "hellooo!\n",
            "hellooo!\n",
            "hellooo!\n",
            "hellooo!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-403-400d4c28ce7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINITIAL_EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-390-6f7f04c4cd94>\u001b[0m in \u001b[0;36mtrain_with_generator\u001b[0;34m(self, data_flow, epochs, steps_per_epoch, run_folder, print_every_n_batches, initial_epoch, lr_decay)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             )\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m       model.distribute_strategy.run(\n\u001b[0;32m--> 817\u001b[0;31m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1283\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1284\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1285\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2831\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2833\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3606\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3607\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3608\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3610\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m       model.distribute_strategy.run(\n\u001b[0;32m--> 817\u001b[0;31m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-390-6f7f04c4cd94>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         training=training_mode):\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    201\u001b[0m     raise ValueError('Layer ' + layer_name + ' expects ' +\n\u001b[1;32m    202\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                      \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                      ' input tensors. Inputs received: ' + str(inputs))\n\u001b[1;32m    205\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer decoder expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(30, 100), dtype=float32, numpy=\narray([[-0.1313759 , -0.01360285, -0.11040404, ...,  0.07136734,\n        -0.01906968, -0.00091979],\n       [-0.15142393, -0.02471823, -0.10543907, ...,  0.07668806,\n        -0.01858885, -0.00509452],\n       [-0.13054483, -0.02769616, -0.10659884, ...,  0.06877746,\n        -0.03876663, -0.00944808],\n       ...,\n       [-0.13881527, -0.03095986, -0.11060996, ...,  0.07654965,\n        -0.02101098, -0.01067327],\n       [-0.12508692, -0.01728634, -0.11369874, ...,  0.06764491,\n        -0.01875212, -0.01467735],\n       [-0.14488736, -0.01965019, -0.10586712, ...,  0.04998093,\n        -0.02567337, -0.00561679]], dtype=float32)>, <tf.Tensor: shape=(30, 100), dtype=float32, numpy=\narray([[-0.05406697,  0.14421505,  0.16325557, ..., -0.02017969,\n        -0.15505973,  0.03693072],\n       [-0.07876325,  0.14486448,  0.16221803, ..., -0.03320931,\n        -0.1517892 ,  0.02665951],\n       [-0.06547226,  0.13578914,  0.1595776 , ..., -0.03182813,\n        -0.15195315,  0.01931921],\n       ...,\n       [-0.05134962,  0.12893216,  0.17288603, ..., -0.0386487 ,\n        -0.14616722,  0.01230677],\n       [-0.05717351,  0.13750853,  0.15468447, ..., -0.02338898,\n        -0.14984855,  0.01091576],\n       [-0.06755193,  0.13518572,  0.16129178, ..., -0.02450443,\n        -0.1314266 ,  0.01939793]], dtype=float32)>, <tf.Tensor: shape=(30, 100), dtype=float32, numpy=\narray([[ 0.46353298, -0.5016709 , -0.64884865, ..., -0.15106563,\n        -0.11650485, -0.75573087],\n       [-0.2808254 ,  0.54350764,  0.51516867, ..., -1.644192  ,\n         1.5354528 , -0.28012574],\n       [-0.15482225, -0.02781637, -0.72020674, ...,  0.6027065 ,\n         0.32902926,  0.19401012],\n       ...,\n       [-0.00814709,  1.0576104 ,  2.45791   , ...,  0.13048854,\n        -0.05601983, -0.06021075],\n       [ 2.130374  , -1.136035  ,  1.5084517 , ..., -0.83184415,\n        -1.1338843 ,  0.13677746],\n       [ 0.767869  , -0.47875667, -0.57333195, ..., -0.7250308 ,\n         0.08172587,  0.7754244 ]], dtype=float32)>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77KUyBTBuClO"
      },
      "source": [
        "n_to_show = 10\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "\n",
        "_,_,z_points = vae.encoder.predict(example_images)\n",
        "\n",
        "reconst_images = vae.decoder.predict(z_points)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = example_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
        "    sub.axis('off')\n",
        "    sub.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=sub.transAxes)\n",
        "            \n",
        "    sub.imshow(img, cmap='gray_r')\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = reconst_images[i].squeeze()\n",
        "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "    sub.axis('off')\n",
        "    sub.imshow(img, cmap='gray_r')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}